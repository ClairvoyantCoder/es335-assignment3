{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df81cd00-facc-49f4-b8ba-00c5deb0e748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sherlock dataset length: 581,423 characters\n",
      "Linux dataset length: 6,206,995 characters\n"
     ]
    }
   ],
   "source": [
    "# 1.1\n",
    "# Load and inspect datasets\n",
    "\n",
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Paths (uploaded files)\n",
    "sherlock_path = Path(\"sherlock_dataset1.txt\")\n",
    "linux_path = Path(\"linux_dataset2.txt\")\n",
    "\n",
    "# Read files\n",
    "sherlock_text = sherlock_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "linux_text = linux_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "print(f\"Sherlock dataset length: {len(sherlock_text):,} characters\")\n",
    "print(f\"Linux dataset length: {len(linux_text):,} characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "329c43ef-03a3-4798-9995-ace647e047f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sherlock tokens: 115,579\n",
      "Linux tokens: 1,001,103\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing functions for natural (Category I) and code (Category II) datasets\n",
    "\n",
    "def preprocess_natural(text: str):\n",
    "    text = re.sub(r\"[^a-zA-Z0-9 \\.]\", \" \", text)   # keep alphanumeric, space, dot\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = text.lower()\n",
    "    text = text.replace(\".\", \" . \")\n",
    "    tokens = re.sub(r\"\\s+\", \" \", text).strip().split(\" \")\n",
    "    return [t for t in tokens if t != \"\"]\n",
    "\n",
    "def preprocess_code(text: str):\n",
    "    tokens = []\n",
    "    for line in text.splitlines():\n",
    "        parts = line.strip().split()\n",
    "        if parts:\n",
    "            tokens.extend(parts)\n",
    "        tokens.append(\"<NL>\")\n",
    "    if tokens and tokens[-1] == \"<NL>\":\n",
    "        tokens.pop()\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing\n",
    "sherlock_tokens = preprocess_natural(sherlock_text)\n",
    "linux_tokens = preprocess_code(linux_text)\n",
    "\n",
    "print(f\"Sherlock tokens: {len(sherlock_tokens):,}\")\n",
    "print(f\"Linux tokens: {len(linux_tokens):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0c1784-595d-40b4-9c81-781d963de612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sherlock vocab size: 8151\n",
      "Linux vocab size: 113645\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(tokens):\n",
    "    counts = Counter(tokens)\n",
    "    vocab = {tok: i for i, tok in enumerate(sorted(counts.keys()))}\n",
    "    inv_vocab = {i: tok for tok, i in vocab.items()}\n",
    "    return vocab, inv_vocab, counts\n",
    "\n",
    "s_vocab, s_inv_vocab, s_counts = build_vocab(sherlock_tokens)\n",
    "l_vocab, l_inv_vocab, l_counts = build_vocab(linux_tokens)\n",
    "\n",
    "print(\"Sherlock vocab size:\", len(s_vocab))\n",
    "print(\"Linux vocab size:\", len(l_vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9764bdb-2bef-4f8e-a3d7-a36cf85005bb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sherlock Datset Most Common Tokens:\n",
      "  token  count\n",
      "0     .   6431\n",
      "1   the   5822\n",
      "2   and   3085\n",
      "3     i   3038\n",
      "4    to   2826\n",
      "5    of   2781\n",
      "6     a   2700\n",
      "7    in   1826\n",
      "8  that   1767\n",
      "9    it   1749\n",
      "Sherlock Datset Least Common Tokens:\n",
      "  token  count\n",
      "0  10th      1\n",
      "1    12      1\n",
      "2  12th      1\n",
      "3   140      1\n",
      "4   150      1\n",
      "5  1500      1\n",
      "6  1661      1\n",
      "7   16a      1\n",
      "8    17      1\n",
      "9  1846      1\n",
      "Linux Datset Most Common Tokens:\n",
      "    token   count\n",
      "0    <NL>  241464\n",
      "1       *   33504\n",
      "2       =   28003\n",
      "3       {   18915\n",
      "4      if   17702\n",
      "5       }   16965\n",
      "6     the   16080\n",
      "7      */   13445\n",
      "8      /*   12190\n",
      "9  struct   10997\n",
      "Linux Datset Least Common Tokens:\n",
      "                          token  count\n",
      "0          !!(attr->sched_flags      1\n",
      "1             !!(caps.magic_etc      1\n",
      "2                !!(file->flags      1\n",
      "3                      !!(flags      1\n",
      "4             !!(func_flags.val      1\n",
      "5                !!(iter->flags      1\n",
      "6  !!(kprobe_gone(&tk->rp.kp));      1\n",
      "7          !!(me->mm->def_flags      1\n",
      "8                !!(trace_flags      1\n",
      "9            !!(vcaps.magic_etc      1\n"
     ]
    }
   ],
   "source": [
    "def top_bottom_counts(counts, k=10):\n",
    "    most_common = counts.most_common(k)\n",
    "    least_common = sorted(counts.items(), key=lambda x: (x[1], x[0]))[:k]\n",
    "    return most_common, least_common\n",
    "\n",
    "s_most, s_least = top_bottom_counts(s_counts)\n",
    "l_most, l_least = top_bottom_counts(l_counts)\n",
    "\n",
    "print(\"Sherlock Datset Most Common Tokens:\")\n",
    "print(pd.DataFrame(s_most, columns=[\"token\", \"count\"]).head(10))\n",
    "print(\"Sherlock Datset Least Common Tokens:\")\n",
    "print(pd.DataFrame(s_least, columns=[\"token\", \"count\"]).head(10))\n",
    "print(\"Linux Datset Most Common Tokens:\")\n",
    "print(pd.DataFrame(l_most, columns=[\"token\", \"count\"]).head(10))\n",
    "print(\"Linux Datset Least Common Tokens:\")\n",
    "print(pd.DataFrame(l_least, columns=[\"token\", \"count\"]).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805603a5-2d45-41b1-9f8e-300d17fe24b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sherlock training pairs: 115574\n",
      "Linux training pairs: 1001098\n"
     ]
    }
   ],
   "source": [
    "def make_xy(tokens, vocab, context_len=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(tokens) - context_len):\n",
    "        X.append([vocab[t] for t in tokens[i:i+context_len]])\n",
    "        y.append(vocab[tokens[i+context_len]])\n",
    "    return X, y\n",
    "\n",
    "CONTEXT_LEN = 5\n",
    "sX, sy = make_xy(sherlock_tokens, s_vocab, CONTEXT_LEN)\n",
    "lX, ly = make_xy(linux_tokens, l_vocab, CONTEXT_LEN)\n",
    "\n",
    "print(\"Sherlock training pairs:\", len(sX))\n",
    "print(\"Linux training pairs:\", len(lX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97dfc025-4516-4e45-ac6e-d05371f45187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sherlock Sample Pairs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the project gutenberg ebook of</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>project gutenberg ebook of the</td>\n",
       "      <td>adventures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gutenberg ebook of the adventures</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebook of the adventures of</td>\n",
       "      <td>sherlock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of the adventures of sherlock</td>\n",
       "      <td>holmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the adventures of sherlock holmes</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adventures of sherlock holmes by</td>\n",
       "      <td>arthur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of sherlock holmes by arthur</td>\n",
       "      <td>conan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sherlock holmes by arthur conan</td>\n",
       "      <td>doyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>holmes by arthur conan doyle</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             context      target\n",
       "0     the project gutenberg ebook of         the\n",
       "1     project gutenberg ebook of the  adventures\n",
       "2  gutenberg ebook of the adventures          of\n",
       "3         ebook of the adventures of    sherlock\n",
       "4      of the adventures of sherlock      holmes\n",
       "5  the adventures of sherlock holmes          by\n",
       "6   adventures of sherlock holmes by      arthur\n",
       "7       of sherlock holmes by arthur       conan\n",
       "8    sherlock holmes by arthur conan       doyle\n",
       "9       holmes by arthur conan doyle        this"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux Sample Pairs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/* &lt;NL&gt; * linux/kernel/irq/autoprobe.c &lt;NL&gt;</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;NL&gt; * linux/kernel/irq/autoprobe.c &lt;NL&gt; *</td>\n",
       "      <td>&lt;NL&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* linux/kernel/irq/autoprobe.c &lt;NL&gt; * &lt;NL&gt;</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linux/kernel/irq/autoprobe.c &lt;NL&gt; * &lt;NL&gt; *</td>\n",
       "      <td>Copyright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;NL&gt; * &lt;NL&gt; * Copyright</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       context     target\n",
       "0  /* <NL> * linux/kernel/irq/autoprobe.c <NL>          *\n",
       "1   <NL> * linux/kernel/irq/autoprobe.c <NL> *       <NL>\n",
       "2   * linux/kernel/irq/autoprobe.c <NL> * <NL>          *\n",
       "3   linux/kernel/irq/autoprobe.c <NL> * <NL> *  Copyright\n",
       "4                      <NL> * <NL> * Copyright        (C)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preview_pairs(inv_vocab, X, y, n=5):\n",
    "    examples = []\n",
    "    for i in range(n):\n",
    "        ctx = \" \".join([inv_vocab[idx] for idx in X[i]])\n",
    "        tgt = inv_vocab[y[i]]\n",
    "        examples.append({\"context\": ctx, \"target\": tgt})\n",
    "    return pd.DataFrame(examples)\n",
    "\n",
    "print(\"Sherlock Sample Pairs:\")\n",
    "display(preview_pairs(s_inv_vocab, sX, sy, n=10))\n",
    "\n",
    "print(\"Linux Sample Pairs:\")\n",
    "display(preview_pairs(l_inv_vocab, lX, ly, n=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dd6774b-ac33-4106-8f83-205c0fe5ebae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preprocessed data and vocab files locally.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def save_json(obj, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f)\n",
    "\n",
    "# Save everything\n",
    "save_json(sherlock_tokens, \"sherlock_tokens.json\")\n",
    "save_json(s_vocab, \"sherlock_vocab.json\")\n",
    "save_json(s_inv_vocab, \"sherlock_inv_vocab.json\")\n",
    "save_json(sX, \"sherlock_X.json\")\n",
    "save_json(sy, \"sherlock_y.json\")\n",
    "\n",
    "save_json(linux_tokens, \"linux_tokens.json\")\n",
    "save_json(l_vocab, \"linux_vocab.json\")\n",
    "save_json(l_inv_vocab, \"linux_inv_vocab.json\")\n",
    "save_json(lX, \"linux_X.json\")\n",
    "save_json(ly, \"linux_y.json\")\n",
    "\n",
    "print(\"Saved preprocessed data and vocab files locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7795f969-3c3b-4dcf-bfb2-53a183cc0c83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
